{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Student Information\n",
    "Name: Didier Fernando Salazar Estrada - 利 葉\n",
    "\n",
    "Student ID: 111065427\n",
    "\n",
    "GitHub ID: difersalest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instructions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. First: do the **take home** exercises in the [DM2022-Lab1-Master](https://github.com/keziatamus/DM2022-Lab1-Master). You may need to copy some cells from the Lab notebook to this notebook. __This part is worth 20% of your grade.__\n",
    "\n",
    "\n",
    "2. Second: follow the same process from the [DM2022-Lab1-Master](https://github.com/keziatamus/DM2022-Lab1-Master) on **the new dataset**. You don't need to explain all details as we did (some **minimal comments** explaining your code are useful though).  __This part is worth 30% of your grade.__\n",
    "    - Download the [the new dataset](https://archive.ics.uci.edu/ml/datasets/Sentiment+Labelled+Sentences#). The dataset contains a `sentence` and `score` label. Read the specificiations of the dataset for details. \n",
    "    - You are allowed to use and modify the `helper` functions in the folder of the first lab session (notice they may need modification) or create your own.\n",
    "\n",
    "\n",
    "3. Third: please attempt the following tasks on **the new dataset**. __This part is worth 30% of your grade.__\n",
    "    - Generate meaningful **new data visualizations**. Refer to online resources and the Data Mining textbook for inspiration and ideas. \n",
    "    - Generate **TF-IDF features** from the tokens of each text. This will generating a document matrix, however, the weights will be computed differently (using the TF-IDF value of each word per document as opposed to the word frequency). Refer to this Sciki-learn [guide](http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html) .\n",
    "    - Implement a simple **Naive Bayes classifier** that automatically classifies the records into their categories. Use both the TF-IDF features and word frequency features to build two seperate classifiers. Comment on the differences.  Refer to this [article](https://hub.packtpub.com/implementing-3-naive-bayes-classifiers-in-scikit-learn/).\n",
    "\n",
    "\n",
    "4. Fourth: In the lab, we applied each step really quickly just to illustrate how to work with your dataset. There are somethings that are not ideal or the most efficient/meaningful. Each dataset can be habdled differently as well. What are those inefficent parts you noticed? How can you improve the Data preprocessing for these specific datasets? __This part is worth 10% of your grade.__\n",
    "\n",
    "\n",
    "5. Fifth: It's hard for us to follow if your code is messy, so please **tidy up your notebook** and **add minimal comments where needed**. __This part is worth 10% of your grade.__\n",
    "\n",
    "\n",
    "You can submit your homework following these guidelines: [Git Intro & How to hand your homework](https://github.com/keziatamus/DM2022-Lab1-Homework/blob/main/Git%20Intro%20%26%20How%20to%20hand%20your%20homework.ipynb). Make sure to commit and save your changes to your repository __BEFORE the deadline (October 20th 11:59 pm, Thursday)__. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "### Begin Assignment Here\n",
    "# TEST necessary for when working with external scripts\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We start by importing our data from the text files as lists, each line corresponds to an item in the list\n",
    "with open('amazon_cells_labelled.txt') as f:\n",
    "    amazon = f.readlines()\n",
    "with open('imdb_labelled.txt') as f:\n",
    "    imdb = f.readlines()\n",
    "with open('yelp_labelled.txt') as f:\n",
    "    yelp = f.readlines()\n",
    "\n",
    "#Now we want to split the corresponding data into the two categories, the sentence and its corresponding score \n",
    "amazon_sep=[]\n",
    "imdb_sep=[]\n",
    "yelp_sep=[]\n",
    "amazon_sent=[]\n",
    "imdb_sent=[]\n",
    "yelp_sent=[]\n",
    "amazon_score=[]\n",
    "imdb_score=[]\n",
    "yelp_score=[]\n",
    "#We navigate into the lists, clear the data by eliminating the '\\n' at the end and split into two columns following the format '\\t'.\n",
    "#In this way we will have from one side the sentence and in the other the score.\n",
    "for x in range(len(amazon)):\n",
    "    amazon_sep.append(amazon[x].removesuffix('\\n').split('\\t'))\n",
    "    imdb_sep.append(imdb[x].removesuffix('\\n').split('\\t'))\n",
    "    yelp_sep.append(yelp[x].removesuffix('\\n').split('\\t'))\n",
    "\n",
    "#We separate the sentences and scores accordingly to create the categories later\n",
    "sentences=[]\n",
    "scores=[]\n",
    "for x in range(len(amazon_sep)):\n",
    "    amazon_sent.append(amazon_sep[x][0])\n",
    "    amazon_score.append(amazon_sep[x][1])\n",
    "    imdb_sent.append(imdb_sep[x][0])\n",
    "    imdb_score.append(imdb_sep[x][1])\n",
    "    yelp_sent.append(yelp_sep[x][0])\n",
    "    yelp_score.append(yelp_sep[x][1])\n",
    "\n",
    "#We integrate the sentences and scores accordingly from each site\n",
    "sentences.extend(amazon_sent)\n",
    "sentences.extend(imdb_sent)\n",
    "sentences.extend(yelp_sent)\n",
    "scores.extend(amazon_score)\n",
    "scores.extend(imdb_score)\n",
    "scores.extend(yelp_score)\n",
    "\n",
    "\n",
    "#Because every sentence and score is separated each every 1000 item in the list we can create new categories, naming them for each site in that order too.\n",
    "#Category 0 for amazon, 1 for imdb, 2 for yelp\n",
    "category=[]\n",
    "category_name=[]\n",
    "for x in range(3000):\n",
    "    if x<1000:\n",
    "        category.append(0)\n",
    "        category_name.append('amazon')\n",
    "    if x>=1000 and x<2000:\n",
    "        category.append(1)\n",
    "        category_name.append('imdb')\n",
    "    if x>=2000 and x<3000:\n",
    "        category.append(2)\n",
    "        category_name.append('yelp')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentences</th>\n",
       "      <th>Score</th>\n",
       "      <th>Category</th>\n",
       "      <th>Category_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>So there is no way for me to plug it in here i...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>amazon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Good case, Excellent value.</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>amazon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Great for the jawbone.</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>amazon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Tied to charger for conversations lasting more...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>amazon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The mic is great.</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>amazon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2995</th>\n",
       "      <td>I think food should have flavor and texture an...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>yelp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2996</th>\n",
       "      <td>Appetite instantly gone.</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>yelp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2997</th>\n",
       "      <td>Overall I was not impressed and would not go b...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>yelp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2998</th>\n",
       "      <td>The whole experience was underwhelming, and I ...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>yelp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2999</th>\n",
       "      <td>Then, as if I hadn't wasted enough of my life ...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>yelp</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3000 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Sentences Score  Category  \\\n",
       "0     So there is no way for me to plug it in here i...     0         0   \n",
       "1                           Good case, Excellent value.     1         0   \n",
       "2                                Great for the jawbone.     1         0   \n",
       "3     Tied to charger for conversations lasting more...     0         0   \n",
       "4                                     The mic is great.     1         0   \n",
       "...                                                 ...   ...       ...   \n",
       "2995  I think food should have flavor and texture an...     0         2   \n",
       "2996                           Appetite instantly gone.     0         2   \n",
       "2997  Overall I was not impressed and would not go b...     0         2   \n",
       "2998  The whole experience was underwhelming, and I ...     0         2   \n",
       "2999  Then, as if I hadn't wasted enough of my life ...     0         2   \n",
       "\n",
       "     Category_name  \n",
       "0           amazon  \n",
       "1           amazon  \n",
       "2           amazon  \n",
       "3           amazon  \n",
       "4           amazon  \n",
       "...            ...  \n",
       "2995          yelp  \n",
       "2996          yelp  \n",
       "2997          yelp  \n",
       "2998          yelp  \n",
       "2999          yelp  \n",
       "\n",
       "[3000 rows x 4 columns]"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "#Here is the data frame, with the columns made by the sentences, scores, the category assigned and the respective name of the site where the reviews where done.\n",
    "X = pd.DataFrame(sentences,columns=['Sentences'])\n",
    "X['Score']=scores\n",
    "X['Category']=category\n",
    "X['Category_name']=category_name\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
